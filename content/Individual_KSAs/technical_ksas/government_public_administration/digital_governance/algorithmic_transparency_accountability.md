---
ksa_id: algorithmic_transparency_accountability
label: Algorithmic Transparency & Accountability
category: Technical
sector: Government_Public_Administration
horizon: emerging
cluster_tags:
  - "AI Governance"
  - "Transparency"
description: >
  Evaluates, documents, and discloses automated-decision systems per NIST’s AI Risk Management Framework and OECD AI Principles, ensuring explainability, bias mitigation, and due-process safeguards.
source_frameworks:
  - "NIST AI Risk Management Framework (AI RMF 1.0)"
  - "OECD AI Principles"
proficiency_levels:
  - level: Awareness
    indicator: Defines​ automated decision vs. decision support; lists key risks (bias, opacity).
  - level: Basic
    indicator: Completes AI system inventory; publishes model cards; provides user recourse channel.
  - level: Intermediate
    indicator: Runs fairness tests; applies explainable-AI (XAI) tools; drafts impact assessments.
  - level: Advanced
    indicator: Aligns models with AI RMF functions (MAP–MEASURE–MANAGE–GOVERN); engages civil-society audits.
  - level: Expert
    indicator: Leads cross-agency AI-governance board; sets transparency policy; mentors auditors and data scientists.
---